{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e243ceae-8bd9-49e3-80d3-34c61b982f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as extra_datetime\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import apimoex\n",
    "import time\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "FMP_API_KEY = \"uILltAaGY2ms0reL0RVtgtALlh2BbYH5\"\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\" # driver path\n",
    "parent_dir = r\"C:\\Users\\Никита\\Андан\\Project\\data\" # root for data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39ac72-e52f-4240-9972-bed79141e5f7",
   "metadata": {},
   "source": [
    "## Stock quotes parser\n",
    "API MOEX and US markets (through FMP API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4521541e-5ffd-478c-8e57-5b57c2be6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |sector|country|ticker|...|\n",
    "companies = pd.read_csv('companies_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_ru = companies[companies.country == 'RU']\n",
    "companies_ru.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4673f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tickers(companies, fmp_api_keys):\n",
    "    '''\n",
    "    This function is needed for parsing stock quotes for the studied period of time.\n",
    "    '''\n",
    "    # Sets the trading board mode as 'TQBR' which is intended for highly liquid and capitalized shares.\n",
    "    board = 'TQBR'\n",
    "    today = str(datetime.date.today())\n",
    "\n",
    "    # Russian companies are filtered from a given dataset and subsequently code iterates through them\n",
    "    companies_ru = companies[companies.country == 'RU']\n",
    "    with requests.Session() as session:\n",
    "        for indx, row in tqdm(companies_ru.iterrows(), desc = 'Processing russian stock', total = companies_ru.shape[0]):\n",
    "            \n",
    "            # To retrieve the trading history for a specified security in a given trading mode over a specified date range.\n",
    "            # Important to specify the \"internet connection session\", the ticker of the security, and the trading mode (by default T+2)\n",
    "            # Result: A list of dictionaries that can be directly converted into a pandas.DataFrame\n",
    "            data = apimoex.get_board_history(session, row.ticker, board=board)\n",
    "            \n",
    "            if data == []:\n",
    "                print('Empty set')\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Depending on the company's sector, code saves the DataFrame to a specific CSV file \n",
    "            # categorized by sector, which facilitates easy data management and access.\n",
    "            if row.sector == 'Renewable Energy':\n",
    "                df.to_csv(path.join(parent_dir, 'renewable_energy', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Healthcare':\n",
    "                df.to_csv(path.join(parent_dir, 'healthcare_services', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Financial Services':\n",
    "                df.to_csv(path.join(parent_dir, 'fintech', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Industrials':\n",
    "                df.to_csv(path.join(parent_dir, 'industrial_goods', f'{row.ticker}_RU.csv'))\n",
    "    \n",
    "    # The function separates American companies from the dataset\n",
    "    companies_usa = companies[companies.country == 'USA']\n",
    "    \n",
    "    # Function get_data fetches historical stock data from the FMP API \n",
    "    # for a given ticker, handling API key rotation upon limit reaching.\n",
    "    def get_data(ticker, today):\n",
    "        for key in fmp_api_keys:\n",
    "            try:\n",
    "                link = f\"https://financialmodelingprep.com/api/v3/historical-chart/4hour/{ticker}?to={today}&apikey={key}\"\n",
    "                return pd.DataFrame(requests.get(link).json(), index=[0])\n",
    "            except requests.HTTPError as e:\n",
    "                print(f\"API key limit reached for {key}, switching keys.\")\n",
    "                continue\n",
    "            \n",
    "    for indx, row in tqdm(companies_usa.iterrows(), desc='Processing USA stock', total=companies_usa.shape[0]):\n",
    "        try:\n",
    "            df = get_data(row.ticker, today)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "\n",
    "        if row.sector == 'Renewable Energy':\n",
    "            df.to_csv(path.join(parent_dir, 'renewable_energy', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Healthcare':\n",
    "            df.to_csv(path.join(parent_dir, 'healthcare_services', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Financial Services':\n",
    "            df.to_csv(path.join(parent_dir, 'fintech', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Industrials':\n",
    "            df.to_csv(path.join(parent_dir, 'industrial_goods', f'{row.ticker}_USA.csv'))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f86ae0-2c69-47e9-a649-2d808ba8978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e261f1eaf743b9ae22dd0b1080f009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing russian stock:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2961af2aeb4a6ea82faac088579406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing USA stock:   0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped for 25 hours\n"
     ]
    }
   ],
   "source": [
    "FMP_API_KEYS = [FMP_API_KEY_1, FMP_API_KEY_2]\n",
    "parse_tickers(companies, FMP_API_KEYS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1a478",
   "metadata": {},
   "source": [
    "## USD/RUB parser\n",
    "CBR XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_usdrub():\n",
    "    '''\n",
    "    This function is needed for parsing USD/RUB exchange rate for the studied period of time.\n",
    "    '''\n",
    "    # Dates in DD/MM/YYYY format\n",
    "    start_date = datetime.date(2010, 1, 1).strftime('%d/%m/%Y')\n",
    "    end_date = datetime.date.today().strftime('%d/%m/%Y')\n",
    "    \n",
    "    # URL creating for the further request\n",
    "    url = f'https://www.cbr.ru/scripts/XML_dynamic.asp?date_req1={start_date}&date_req2={end_date}&VAL_NM_RQ=R01235'\n",
    "    response_usd = requests.get(url)\n",
    "    \n",
    "    tree_usd_rate = BeautifulSoup(response_usd.content, 'html.parser')\n",
    "    \n",
    "    dates = []\n",
    "    usd_rates = []\n",
    "    \n",
    "    # Forms two sets with dates and exchange rates, that will be used for final dataframe\n",
    "    for line in tree_usd_rate.find_all('record'):\n",
    "        dates.append(extra_datetime.strptime(line.get('date'), '%d.%m.%Y').date().strftime('%d.%m.%Y'))\n",
    "        usd_rates.append(float(line.value.text.replace(',', '.')))\n",
    "    \n",
    "    usdrub = pd.DataFrame(data=usd_rates, index=pd.to_datetime(dates), columns=['usdrub'])\n",
    "    usdrub_final = usdrub.sort_index()\n",
    "    \n",
    "    # Code saves the result to CSV file\n",
    "    usdrub_final.to_csv(path.join(parent_dir, 'usdrub_rates', 'data_usdrub.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ea1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_usdrub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a5ca0-7616-4a2a-a663-574cfdc23759",
   "metadata": {},
   "source": [
    "## Trading calendar parsing\n",
    "\n",
    "Below one can fing example of parsing trading calendar for NYSE stock market. Later it will be implemented in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a2245-8314-4277-8fd2-93d29e2f8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas_market_calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7fe3b73-16ce-477e-ba87-f1fa379f9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2014-01-01'\n",
    "end_date = str(datetime.date.today())\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89744ea6-f1f4-42ca-9120-09b855e14e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_open</th>\n",
       "      <th>market_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>2014-01-02 14:30:00+00:00</td>\n",
       "      <td>2014-01-02 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>2014-01-03 14:30:00+00:00</td>\n",
       "      <td>2014-01-03 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>2014-01-06 14:30:00+00:00</td>\n",
       "      <td>2014-01-06 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>2014-01-07 14:30:00+00:00</td>\n",
       "      <td>2014-01-07 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>2014-01-08 14:30:00+00:00</td>\n",
       "      <td>2014-01-08 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30</th>\n",
       "      <td>2024-04-30 13:30:00+00:00</td>\n",
       "      <td>2024-04-30 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01</th>\n",
       "      <td>2024-05-01 13:30:00+00:00</td>\n",
       "      <td>2024-05-01 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02</th>\n",
       "      <td>2024-05-02 13:30:00+00:00</td>\n",
       "      <td>2024-05-02 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03</th>\n",
       "      <td>2024-05-03 13:30:00+00:00</td>\n",
       "      <td>2024-05-03 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-06</th>\n",
       "      <td>2024-05-06 13:30:00+00:00</td>\n",
       "      <td>2024-05-06 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2603 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         market_open              market_close\n",
       "2014-01-02 2014-01-02 14:30:00+00:00 2014-01-02 21:00:00+00:00\n",
       "2014-01-03 2014-01-03 14:30:00+00:00 2014-01-03 21:00:00+00:00\n",
       "2014-01-06 2014-01-06 14:30:00+00:00 2014-01-06 21:00:00+00:00\n",
       "2014-01-07 2014-01-07 14:30:00+00:00 2014-01-07 21:00:00+00:00\n",
       "2014-01-08 2014-01-08 14:30:00+00:00 2014-01-08 21:00:00+00:00\n",
       "...                              ...                       ...\n",
       "2024-04-30 2024-04-30 13:30:00+00:00 2024-04-30 20:00:00+00:00\n",
       "2024-05-01 2024-05-01 13:30:00+00:00 2024-05-01 20:00:00+00:00\n",
       "2024-05-02 2024-05-02 13:30:00+00:00 2024-05-02 20:00:00+00:00\n",
       "2024-05-03 2024-05-03 13:30:00+00:00 2024-05-03 20:00:00+00:00\n",
       "2024-05-06 2024-05-06 13:30:00+00:00 2024-05-06 20:00:00+00:00\n",
       "\n",
       "[2603 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting schedule of NYSE\n",
    "nyse.schedule(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62695ddf-4cc2-488b-927b-e50d51f095a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse.schedule(start_date, end_date).to_csv(path.join(parent_dir, 'trading_calendat_NYSE.csv'), \\\n",
    "                                                     index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4b13df1-4733-4b82-8ff2-a6b0b1bf7fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.datetime64('2200-06-19'),\n",
       " numpy.datetime64('2200-07-04'),\n",
       " numpy.datetime64('2200-09-01'),\n",
       " numpy.datetime64('2200-11-27'),\n",
       " numpy.datetime64('2200-12-25'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting only holidays (exluding wekeends) \n",
    "nyse.holidays().holidays[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0c72473-32ba-446b-8b51-66e7d765a6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2014-01-02 00:00:00+00:00', '2014-01-03 00:00:00+00:00',\n",
       "               '2014-01-06 00:00:00+00:00', '2014-01-07 00:00:00+00:00',\n",
       "               '2014-01-08 00:00:00+00:00', '2014-01-09 00:00:00+00:00',\n",
       "               '2014-01-10 00:00:00+00:00', '2014-01-13 00:00:00+00:00',\n",
       "               '2014-01-14 00:00:00+00:00', '2014-01-15 00:00:00+00:00',\n",
       "               ...\n",
       "               '2024-04-23 00:00:00+00:00', '2024-04-24 00:00:00+00:00',\n",
       "               '2024-04-25 00:00:00+00:00', '2024-04-26 00:00:00+00:00',\n",
       "               '2024-04-29 00:00:00+00:00', '2024-04-30 00:00:00+00:00',\n",
       "               '2024-05-01 00:00:00+00:00', '2024-05-02 00:00:00+00:00',\n",
       "               '2024-05-03 00:00:00+00:00', '2024-05-06 00:00:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', length=2603, freq=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get iterable object of all trading days\n",
    "nyse.valid_days(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37554dcd-0f45-4007-a76c-1deb3fda5f14",
   "metadata": {},
   "source": [
    "## S&P500 and US GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac21848-7b36-4cb2-a26c-ea933577c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alpha_vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f91023-ee06-4f37-b0f1-bbcd6d13a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitation: 25 requests per day\n",
    "key = 'LYET8836ZF7IKTSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2de870b-52fc-45eb-be44-99743a324edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "def USA_index_parsing(save_path, key):\n",
    "    '''\n",
    "    save_path: str or path-object - path to save parsed file\n",
    "    key: str - api_key for AlphaVantageAPI\n",
    "\n",
    "    returns\n",
    "    saves S&P500 historical prices up to date as a csv file \n",
    "    '''\n",
    "    ts = TimeSeries(key) # special alpha vantage api object\n",
    "\n",
    "    # Getting close, high, low, open and volume for S&P500 \n",
    "    # all available historical data\n",
    "    \n",
    "    data, meta_data = ts.get_daily(symbol='SPY', outputsize='full')\n",
    "    df = pd.DataFrame(data).T.reset_index().rename({'index': 'date'}, axis= 1)\n",
    "    for column in df.columns:\n",
    "        if column[0].isdigit():\n",
    "            df.rename({column: column[3:]}, axis = 1, inplace = True)\n",
    "\n",
    "    df.to_csv(path.join(save_path, 'S&P500.csv'), \\\n",
    "              index = False, encoding = 'utf-8')\n",
    "    print('Parsing is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a17c95c3-d690-4795-846f-05da11aeaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_usa_gdp(save_path, key):\n",
    "    '''\n",
    "    save_path: str or path-object - path to save parsed file\n",
    "    key: str - api_key for AlphaVantageAPI\n",
    "\n",
    "    returns\n",
    "    saves real US GDP historical values (quarterly data) as a csv file \n",
    "    '''\n",
    "    # Getting real US GDP through link alpha vantage api\n",
    "    url = f'https://www.alphavantage.co/query?function=REAL_GDP&interval=quarterly&apikey={key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['date'] = df['data'].apply(lambda x: x['date'])\n",
    "    df['value'] = df['data'].apply(lambda x: x['value'])\n",
    "    df.drop('data', axis = 1).to_csv(path.join(save_path, 'GDP_USA.csv'), \\\n",
    "                                     index = False, encoding = 'utf-8')\n",
    "    print('Parsing is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8afa0391-a249-42da-a040-c7443705940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing is done!\n",
      "Parsing is done!\n"
     ]
    }
   ],
   "source": [
    "# example of usage\n",
    "save_path = r'C:\\Users\\Никита\\Андан\\Project\\data\\macro'\n",
    "USA_index_parsing(save_path, key)\n",
    "parse_usa_gdp(save_path, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12a049-79f4-4e4e-a4b0-ac9bbfe383a0",
   "metadata": {},
   "source": [
    "## EFFR\n",
    "\n",
    "Federal Funds Effective Rate. [More about it](https://www.newyorkfed.org/markets/reference-rates/effr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f243bd2-1fb3-4943-be41-8386a5933b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_effr(driver_path, save_path):\n",
    "    '''\n",
    "    driver_path: str or path-object - path to webriver for Selenium\n",
    "    save_path: str or path-object - path to save parsed file\n",
    "\n",
    "    returns \n",
    "    saves EFFR monthly data as a csv file\n",
    "    '''\n",
    "\n",
    "    # extracting link from FRED website\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "    try:\n",
    "        driver.get('https://fred.stlouisfed.org/series/FEDFUNDS')\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"download-button\"))\n",
    "        )\n",
    "        element.click()\n",
    "    \n",
    "        time.sleep(5)\n",
    "        html_content = driver.page_source\n",
    "        driver.quit()\n",
    "    except:\n",
    "        driver.quit()\n",
    "\n",
    "    link = BeautifulSoup(html_content, 'html.parser').\\\n",
    "    find_all('a', {'class': 'dropdown-item fg-download-csv-chart-gtm fg-download-gtm', \\\n",
    "                   'id': \"download-data-csv\"})[0].\\\n",
    "                                                get('href')\n",
    "\n",
    "    # parsing interest rates\n",
    "    responce = requests.get(r'https://fred.stlouisfed.org' + link)\n",
    "    with open(path.join(save_path, 'EFFR.csv'), 'wb') as file:\n",
    "        file.write(responce.content)\n",
    "    \n",
    "    print('Parsing is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ff89020-149d-4ef6-9da7-73a08f064cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing is done!\n"
     ]
    }
   ],
   "source": [
    "parse_effr(PATH, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
