{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df577e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"request_url = ('https://iss.moex.com/iss/engines/stock/'\n",
    "               'markets/shares/boards/TQBR/securities.json')\n",
    "arguments = {'securities.columns': ('SECID,'\n",
    "                                    'REGNUMBER,'\n",
    "                                    'LOTSIZE,'\n",
    "                                    'SHORTNAME')}\n",
    "with requests.Session() as session:\n",
    "    iss = apimoex.ISSClient(session, request_url, arguments)\n",
    "    data = iss.get()\n",
    "    df = pd.DataFrame(data['securities'])\n",
    "    df.set_index('SECID', inplace=True)\n",
    "    print(df)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install apimoex\n",
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243ceae-8bd9-49e3-80d3-34c61b982f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from os import path\n",
    "import pathlib\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as extra_datetime\n",
    "import time\n",
    "\n",
    "import apimoex\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# creating root for data \n",
    "parent_dir = r\"/Users/andrewnizov/Desktop/АнДан/Проект\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39ac72-e52f-4240-9972-bed79141e5f7",
   "metadata": {},
   "source": [
    "## Stock quotes parser\n",
    "API MOEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521541e-5ffd-478c-8e57-5b57c2be6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |sector|country|ticker|...|\n",
    "companies = pd.read_csv('companies_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_ru = companies[companies.country == 'RU']\n",
    "companies_ru.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8dde39-83b0-4fa2-a07e-7fdffffa698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tickers(companies, fmp_api_keys):\n",
    "    '''\n",
    "    This function is needed for parsing stock quotes for the studied period of time.\n",
    "    '''\n",
    "    # Sets the trading board mode as 'TQBR' which is intended for highly liquid and capitalized shares.\n",
    "    board = 'TQBR'\n",
    "    today = str(datetime.date.today())\n",
    "\n",
    "    # Russian companies are filtered from a given dataset and subsequently code iterates through them\n",
    "    companies_ru = companies[companies.country == 'RU']\n",
    "    with requests.Session() as session:\n",
    "        for indx, row in tqdm(companies_ru.iterrows(), desc = 'Processing russian stock', total = companies_ru.shape[0]):\n",
    "            \n",
    "            # To retrieve the trading history for a specified security in a given trading mode over a specified date range.\n",
    "            # Important to specify the \"internet connection session\", the ticker of the security, and the trading mode (by default T+2)\n",
    "            # Result: A list of dictionaries that can be directly converted into a pandas.DataFrame\n",
    "            data = apimoex.get_board_history(session, row.ticker, board=board)\n",
    "            \n",
    "            if data == []:\n",
    "                print('Empty set')\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Depending on the company's sector, code saves the DataFrame to a specific CSV file \n",
    "            # categorized by sector, which facilitates easy data management and access.\n",
    "            if row.sector == 'Renewable Energy':\n",
    "                df.to_csv(path.join(parent_dir, 'renewable_energy', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Healthcare':\n",
    "                df.to_csv(path.join(parent_dir, 'healthcare_services', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Financial Services':\n",
    "                df.to_csv(path.join(parent_dir, 'fintech', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Industrials':\n",
    "                df.to_csv(path.join(parent_dir, 'industrial_goods', f'{row.ticker}_RU.csv'))\n",
    "    \n",
    "    # The function separates American companies from the dataset\n",
    "    companies_usa = companies[companies.country == 'USA']\n",
    "    \n",
    "    # Function get_data fetches historical stock data from the FMP API \n",
    "    # for a given ticker, handling API key rotation upon limit reaching.\n",
    "    def get_data(ticker, today):\n",
    "        for key in fmp_api_keys:\n",
    "            try:\n",
    "                link = f\"https://financialmodelingprep.com/api/v3/historical-chart/4hour/{ticker}?to={today}&apikey={key}\"\n",
    "                return pd.DataFrame(requests.get(link).json(), index=[0])\n",
    "            except requests.HTTPError as e:\n",
    "                print(f\"API key limit reached for {key}, switching keys.\")\n",
    "                continue\n",
    "            \n",
    "    for indx, row in tqdm(companies_usa.iterrows(), desc='Processing USA stock', total=companies_usa.shape[0]):\n",
    "        try:\n",
    "            df = get_data(row.ticker, today)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "\n",
    "        if row.sector == 'Renewable Energy':\n",
    "            df.to_csv(path.join(parent_dir, 'renewable_energy', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Healthcare':\n",
    "            df.to_csv(path.join(parent_dir, 'healthcare_services', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Financial Services':\n",
    "            df.to_csv(path.join(parent_dir, 'fintech', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Industrials':\n",
    "            df.to_csv(path.join(parent_dir, 'industrial_goods', f'{row.ticker}_USA.csv'))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f86ae0-2c69-47e9-a649-2d808ba8978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMP_API_KEYS = [FMP_API_KEY_1, FMP_API_KEY_2]\n",
    "parse_tickers(companies, FMP_API_KEYS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ebf0f",
   "metadata": {},
   "source": [
    "## USD/RUB parser\n",
    "CBR XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ca5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_usdrub():\n",
    "    '''\n",
    "    This function is needed for parsing USD/RUB exchange rate for the studied period of time.\n",
    "    '''\n",
    "    # Dates in DD/MM/YYYY format\n",
    "    start_date = datetime.date(2010, 1, 1).strftime('%d/%m/%Y')\n",
    "    end_date = datetime.date.today().strftime('%d/%m/%Y')\n",
    "    \n",
    "    # URL creating for the further request\n",
    "    url = f'https://www.cbr.ru/scripts/XML_dynamic.asp?date_req1={start_date}&date_req2={end_date}&VAL_NM_RQ=R01235'\n",
    "    response_usd = requests.get(url)\n",
    "    \n",
    "    tree_usd_rate = BeautifulSoup(response_usd.content, 'html.parser')\n",
    "    \n",
    "    dates = []\n",
    "    usd_rates = []\n",
    "    \n",
    "    # Forms two sets with dates and exchange rates, that will be used for final dataframe\n",
    "    for line in tree_usd_rate.find_all('record'):\n",
    "        dates.append(extra_datetime.strptime(line.get('date'), '%d.%m.%Y').date().strftime('%d.%m.%Y'))\n",
    "        usd_rates.append(float(line.value.text.replace(',', '.')))\n",
    "    \n",
    "    usdrub = pd.DataFrame(data=usd_rates, index=pd.to_datetime(dates), columns=['usdrub'])\n",
    "    usdrub_final = usdrub.sort_index()\n",
    "    \n",
    "    # Code saves the result to CSV file\n",
    "    usdrub_final.to_csv(path.join(parent_dir, 'usdrub_rates', 'data_usdrub.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaac962",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_usdrub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90616035",
   "metadata": {},
   "source": [
    "## Precious metals prices parser\n",
    "CBR XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c00b6",
   "metadata": {},
   "source": [
    "* 1 - gold\n",
    "* 2 - silver\n",
    "* 3 - platinum\n",
    "* 4 - palladium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e563c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_precious_metals_rates():\n",
    "    '''\n",
    "    This function is needed for parsing prices of 4 precious metals for the studied period of time.\n",
    "    '''\n",
    "    # Dates in DD/MM/YYYY format\n",
    "    start_date = datetime.date(2010, 1, 1).strftime('%d/%m/%Y')\n",
    "    end_date = datetime.date.today().strftime('%d/%m/%Y')\n",
    "    \n",
    "    # URL creating for the further request\n",
    "    url_1 = f'https://www.cbr.ru/scripts/xml_metall.asp?date_req1={start_date}&date_req2={end_date}'\n",
    "    response_precious = requests.get(url_1)\n",
    "    \n",
    "    tree_precious_rate = BeautifulSoup(response_precious.content, 'html.parser')\n",
    "    \n",
    "    dates = []\n",
    "    gold_rates = []\n",
    "    silver_rates = []\n",
    "    platinum_rates = []\n",
    "    palladium_rates = []\n",
    "    \n",
    "    # Forms five sets with dates and prices of 4 precious metals, that will be used for final dataframe\n",
    "    helpa = 1\n",
    "    for stat in tree_precious_rate.find_all('record'):\n",
    "        if helpa == 1:\n",
    "            gold_rates.append(float(stat.buy.text.replace(',', '.')))\n",
    "            dates.append(extra_datetime.strptime(stat.get('date'), '%d.%m.%Y').date().strftime('%d.%m.%Y'))\n",
    "        elif helpa == 2:\n",
    "            silver_rates.append(float(stat.buy.text.replace(',', '.')))\n",
    "        elif helpa == 3:\n",
    "            platinum_rates.append(float(stat.buy.text.replace(',', '.')))\n",
    "        else:\n",
    "            palladium_rates.append(float(stat.buy.text.replace(',', '.')))\n",
    "\n",
    "        if helpa == 4:\n",
    "            helpa = 0\n",
    "\n",
    "        helpa += 1\n",
    "\n",
    "    precious_metals = pd.DataFrame({'gold_rates': gold_rates, 'silver_rates': silver_rates, 'platinum_rates': platinum_rates, 'palladium_rates': palladium_rates}, index=pd.to_datetime(dates))\n",
    "    final_precious_metals = precious_metals.sort_index()\n",
    "    \n",
    "    return final_precious_metals\n",
    "    \n",
    "    # Code saves the result to CSV file\n",
    "    '''final_precious_metals.to_csv(path.join(parent_dir, 'precious_metals', 'data_precious_metals.csv'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0466897",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_precious_metals_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a391a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_price = parse_precious_metals_rates()['gold_rates']\n",
    "silver_price = parse_precious_metals_rates()['silver_rates']\n",
    "platinum_price = parse_precious_metals_rates()['platinum_rates']\n",
    "palladium_price = parse_precious_metals_rates()['palladium_rates']\n",
    "x = gold_price.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 6))\n",
    "plt.plot(x, palladium_price)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f51d41",
   "metadata": {},
   "source": [
    "## Парсинг календаря расчетных дней \n",
    "для бинарного признака (есть торги/нет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3cc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792b169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecf8f7f9",
   "metadata": {},
   "source": [
    "## Interbank market rates parser\n",
    "CBR XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21faf393",
   "metadata": {},
   "source": [
    "**Code = 3: Weighted average actual rates on ruble loans provided by Moscow banks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_interbank_market_rates():\n",
    "    '''\n",
    "    This function is needed for parsing dynamics of interbank credit market rates for the studied period of time.\n",
    "    '''\n",
    "    # Dates in DD/MM/YYYY format\n",
    "    start_date = datetime.date(2010, 1, 1).strftime('%d/%m/%Y')\n",
    "    end_date = datetime.date.today().strftime('%d/%m/%Y')\n",
    "    \n",
    "    # URL creating for the further request\n",
    "    url_2 = f'https://www.cbr.ru/scripts/xml_mkr.asp?date_req1={start_date}&date_req2={end_date}' \n",
    "    response_credit_rate = requests.get(url_2)\n",
    "    \n",
    "    tree_credit_rate = BeautifulSoup(response_credit_rate.content, 'html.parser')\n",
    "    \n",
    "    dates = []\n",
    "    interbank_credit_market_rates = []\n",
    "    \n",
    "    # Forms two sets with dates and exchange rates, that will be used for final dataframe\n",
    "    # Code appeals to elusive html element, using xml.etree.ElementTree\n",
    "    for line in tree_credit_rate.find_all('record'):\n",
    "        root = ET.fromstring(str(line))\n",
    "        if root.attrib.get('code') == '3':\n",
    "            dates.append(extra_datetime.strptime(line.get('date'), '%d/%m/%Y').date().strftime('%d/%m/%Y'))\n",
    "            if line.c1.text != '-':\n",
    "                interbank_credit_market_rates.append(float(line.c1.text))\n",
    "            else:\n",
    "                interbank_credit_market_rates.append('-')\n",
    "    \n",
    "    interbank_rates = pd.DataFrame(data=interbank_credit_market_rates, index=pd.to_datetime(dates), columns=['Interbank credit market rates'])\n",
    "    interbank_rates_final = interbank_rates.sort_index()\n",
    "    \n",
    "    # Code saves the result to CSV file\n",
    "    interbank_rates_final.to_csv(path.join(parent_dir, 'interbank_credit_market_rates', 'data_interbank_rates.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f30a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_interbank_market_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675ff58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb2a5ca0-7616-4a2a-a663-574cfdc23759",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Парсер FMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe3b73-16ce-477e-ba87-f1fa379f9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'IMPP'\n",
    "date = str(datetime.date.today())\n",
    "APIKEY = \"uILltAaGY2ms0reL0RVtgtALlh2BbYH5\"\n",
    "\n",
    "link = f\"https://financialmodelingprep.com/api/v3/historical-chart/4hour/{ticker}?to={date}&apikey={APIKEY}\"\n",
    "response = requests.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b13df1-4733-4b82-8ff2-a6b0b1bf7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(response.json(), index=[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    for indx, row in tqdm(companies_usa.iterrows(), desc = 'Processing USA stock', total = companies_usa.shape[0]):\n",
    "        try:\n",
    "            link = f\"https://financialmodelingprep.com/api/v3/historical-chart/4hour/{row.ticker}?to={today}&apikey={fmp_api_keys[0]}\"\n",
    "            df = pd.DataFrame(requests.get(link).json())\n",
    "        except ValueError:\n",
    "            link = f\"https://financialmodelingprep.com/api/v3/historical-chart/4hour/{row.ticker}?to={today}&apikey={fmp_api_keys[1]}\"\n",
    "            df = pd.DataFrame(requests.get(link).json())'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
