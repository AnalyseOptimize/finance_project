{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e243ceae-8bd9-49e3-80d3-34c61b982f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as extra_datetime\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import apimoex\n",
    "import time\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "FMP_API_KEY = \"uILltAaGY2ms0reL0RVtgtALlh2BbYH5\"\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\" # driver path\n",
    "parent_dir = r\"C:\\Users\\Никита\\Андан\\Project\\data\" # root for data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39ac72-e52f-4240-9972-bed79141e5f7",
   "metadata": {},
   "source": [
    "## Stock quotes parser\n",
    "API MOEX and US markets (through FMP API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4521541e-5ffd-478c-8e57-5b57c2be6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |sector|country|ticker|...|\n",
    "companies = pd.read_csv('companies_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "334dc04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_ru = companies[companies.country == 'RU']\n",
    "companies_ru.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357a36ab-d0f2-42d7-b5a5-0ef698166ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=requests.get('https://financialmodelingprep.com/api/v3/historical-price-full/AAPL?apikey=uILltAaGY2ms0reL0RVtgtALlh2BbYH5')\n",
    "df = pd.DataFrame(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299ced4d-d850-41e9-9619-7b36892e7783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>historical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-05-08', 'open': 182.85, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-05-07', 'open': 183.45, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-05-06', 'open': 182.35, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-05-03', 'open': 186.65, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-05-02', 'open': 172.51, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-05-15', 'open': 46.57, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-05-14', 'open': 46.6, 'high': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-05-13', 'open': 46.93, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-05-10', 'open': 49.36, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-05-09', 'open': 50.1, 'high': 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                                         historical\n",
       "0      AAPL  {'date': '2024-05-08', 'open': 182.85, 'high':...\n",
       "1      AAPL  {'date': '2024-05-07', 'open': 183.45, 'high':...\n",
       "2      AAPL  {'date': '2024-05-06', 'open': 182.35, 'high':...\n",
       "3      AAPL  {'date': '2024-05-03', 'open': 186.65, 'high':...\n",
       "4      AAPL  {'date': '2024-05-02', 'open': 172.51, 'high':...\n",
       "...     ...                                                ...\n",
       "1254   AAPL  {'date': '2019-05-15', 'open': 46.57, 'high': ...\n",
       "1255   AAPL  {'date': '2019-05-14', 'open': 46.6, 'high': 4...\n",
       "1256   AAPL  {'date': '2019-05-13', 'open': 46.93, 'high': ...\n",
       "1257   AAPL  {'date': '2019-05-10', 'open': 49.36, 'high': ...\n",
       "1258   AAPL  {'date': '2019-05-09', 'open': 50.1, 'high': 5...\n",
       "\n",
       "[1259 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4673f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tickers(companies, fmp_api_keys):\n",
    "    '''\n",
    "    This function is needed for parsing stock quotes for the studied period of time.\n",
    "    '''\n",
    "    # Sets the trading board mode as 'TQBR' which is intended for highly liquid and capitalized shares.\n",
    "    board = 'TQBR'\n",
    "    today = str(datetime.date.today())\n",
    "\n",
    "    # Russian companies are filtered from a given dataset and subsequently code iterates through them\n",
    "    companies_ru = companies[companies.country == 'RU']\n",
    "    with requests.Session() as session:\n",
    "        for indx, row in tqdm(companies_ru.iterrows(), desc = 'Processing russian stock', total = companies_ru.shape[0]):\n",
    "            \n",
    "            # To retrieve the trading history for a specified security in a given trading mode over a specified date range.\n",
    "            # Important to specify the \"internet connection session\", the ticker of the security, and the trading mode (by default T+2)\n",
    "            # Result: A list of dictionaries that can be directly converted into a pandas.DataFrame\n",
    "            data = apimoex.get_board_history(session, row.ticker, board=board)\n",
    "            \n",
    "            if data == []:\n",
    "                print('Empty set')\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Depending on the company's sector, code saves the DataFrame to a specific CSV file \n",
    "            # categorized by sector, which facilitates easy data management and access.\n",
    "            if row.sector == 'Renewable Energy':\n",
    "                df.to_csv(path.join(parent_dir, 'renewable_energy', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Healthcare':\n",
    "                df.to_csv(path.join(parent_dir, 'healthcare_services', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Financial Services':\n",
    "                df.to_csv(path.join(parent_dir, 'fintech', f'{row.ticker}_RU.csv'))\n",
    "            elif row.sector == 'Industrials':\n",
    "                df.to_csv(path.join(parent_dir, 'industrial_goods', f'{row.ticker}_RU.csv'))\n",
    "    \n",
    "    # The function separates American companies from the dataset\n",
    "    companies_usa = companies[companies.country == 'USA']\n",
    "    \n",
    "    # Function get_data fetches historical stock data from the FMP API \n",
    "    # for a given ticker, handling API key rotation upon limit reaching.\n",
    "    def get_data(ticker, today):\n",
    "        for key in fmp_api_keys:\n",
    "            try:\n",
    "                link = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?apikey={key}\"\n",
    "                df = pd.DataFrame(requests.get(link).json())\n",
    "                df['date'] = df['historical'].apply(lambda x: x['date'])\n",
    "                df['open'] = df['historical'].apply(lambda x: x['open'])\n",
    "                df['close'] = df['historical'].apply(lambda x: x['close'])\n",
    "                df['volume'] = df['historical'].apply(lambda x: x['volume'])\n",
    "                df = df[['date', 'open', 'close', 'volume']]\n",
    "                return df\n",
    "            except ValueError as e:\n",
    "                print(f\"API key limit reached for {key}, switching keys.\")\n",
    "                continue\n",
    "            \n",
    "    for indx, row in tqdm(companies_usa.iterrows(), desc='Processing USA stock', total=companies_usa.shape[0]):\n",
    "        try:\n",
    "            df = get_data(row.ticker, today)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "\n",
    "        if row.sector == 'Renewable Energy':\n",
    "            df.to_csv(path.join(parent_dir, 'renewable_energy', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Healthcare':\n",
    "            df.to_csv(path.join(parent_dir, 'healthcare_services', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Financial Services':\n",
    "            df.to_csv(path.join(parent_dir, 'fintech', f'{row.ticker}_USA.csv'))\n",
    "        elif row.sector == 'Industrials':\n",
    "            df.to_csv(path.join(parent_dir, 'industrial_goods', f'{row.ticker}_USA.csv'))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f86ae0-2c69-47e9-a649-2d808ba8978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf8abcb219947ef9b806d8b45092cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing russian stock:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cd728fd3404da18f6e5e05daf9a327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing USA stock: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMP_API_KEY_1 = \"uILltAaGY2ms0reL0RVtgtALlh2BbYH5\"\n",
    "FMP_API_KEY_2 = 'bPovzfDRx9s9Udj9p1yaVGmLaKNq3KXw'\n",
    "FMP_API_KEY_3 = 'Q9e9dv5UrDiwgEF01HZSpBz68suGulAo'\n",
    "FMP_API_KEY_4 = '1Q2quurK6FK8BVqmVKVz7nipgaKFzlUu'\n",
    "FMP_API_KEY_5 = 'RmDeOfi7CudN1cC3eVcGPfRNxqdqhWgr'\n",
    "FMP_API_KEYS = [FMP_API_KEY_1, FMP_API_KEY_2, FMP_API_KEY_3, FMP_API_KEY_4, FMP_API_KEY_5]\n",
    "parse_tickers(companies, FMP_API_KEYS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed8adfe7-e548-4a8a-bdbe-ae4eac0a373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = companies[companies.country == 'USA'].loc[239].ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1e489c6-f066-40d4-a2f0-8af996b15f77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://financialmodelingprep.com/api/v3/historical-chart/4hour/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?to=2024-01-01&apikey=uILltAaGY2ms0reL0RVtgtALlh2BbYH5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\conda\\envs\\new_env\\lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mD:\\conda\\envs\\new_env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\conda\\envs\\new_env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mD:\\conda\\envs\\new_env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:645\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    648\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "link = f\"https://financialmodelingprep.com/api/v3/historical-chart/4hour/{ticker}?to=2024-01-01&apikey=uILltAaGY2ms0reL0RVtgtALlh2BbYH5\"\n",
    "pd.DataFrame(requests.get(link).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1a478",
   "metadata": {},
   "source": [
    "## USD/RUB parser\n",
    "CBR XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_usdrub():\n",
    "    '''\n",
    "    This function is needed for parsing USD/RUB exchange rate for the studied period of time.\n",
    "    '''\n",
    "    # Dates in DD/MM/YYYY format\n",
    "    start_date = datetime.date(2010, 1, 1).strftime('%d/%m/%Y')\n",
    "    end_date = datetime.date.today().strftime('%d/%m/%Y')\n",
    "    \n",
    "    # URL creating for the further request\n",
    "    url = f'https://www.cbr.ru/scripts/XML_dynamic.asp?date_req1={start_date}&date_req2={end_date}&VAL_NM_RQ=R01235'\n",
    "    response_usd = requests.get(url)\n",
    "    \n",
    "    tree_usd_rate = BeautifulSoup(response_usd.content, 'html.parser')\n",
    "    \n",
    "    dates = []\n",
    "    usd_rates = []\n",
    "    \n",
    "    # Forms two sets with dates and exchange rates, that will be used for final dataframe\n",
    "    for line in tree_usd_rate.find_all('record'):\n",
    "        dates.append(extra_datetime.strptime(line.get('date'), '%d.%m.%Y').date().strftime('%d.%m.%Y'))\n",
    "        usd_rates.append(float(line.value.text.replace(',', '.')))\n",
    "    \n",
    "    usdrub = pd.DataFrame(data=usd_rates, index=pd.to_datetime(dates), columns=['usdrub'])\n",
    "    usdrub_final = usdrub.sort_index()\n",
    "    \n",
    "    # Code saves the result to CSV file\n",
    "    usdrub_final.to_csv(path.join(parent_dir, 'usdrub_rates', 'data_usdrub.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ea1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_usdrub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a5ca0-7616-4a2a-a663-574cfdc23759",
   "metadata": {},
   "source": [
    "## Trading calendar parsing\n",
    "\n",
    "Below one can fing example of parsing trading calendar for NYSE stock market. Later it will be implemented in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a2245-8314-4277-8fd2-93d29e2f8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas_market_calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7fe3b73-16ce-477e-ba87-f1fa379f9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2014-01-01'\n",
    "end_date = str(datetime.date.today())\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89744ea6-f1f4-42ca-9120-09b855e14e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_open</th>\n",
       "      <th>market_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>2014-01-02 14:30:00+00:00</td>\n",
       "      <td>2014-01-02 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>2014-01-03 14:30:00+00:00</td>\n",
       "      <td>2014-01-03 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>2014-01-06 14:30:00+00:00</td>\n",
       "      <td>2014-01-06 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>2014-01-07 14:30:00+00:00</td>\n",
       "      <td>2014-01-07 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>2014-01-08 14:30:00+00:00</td>\n",
       "      <td>2014-01-08 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30</th>\n",
       "      <td>2024-04-30 13:30:00+00:00</td>\n",
       "      <td>2024-04-30 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01</th>\n",
       "      <td>2024-05-01 13:30:00+00:00</td>\n",
       "      <td>2024-05-01 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02</th>\n",
       "      <td>2024-05-02 13:30:00+00:00</td>\n",
       "      <td>2024-05-02 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03</th>\n",
       "      <td>2024-05-03 13:30:00+00:00</td>\n",
       "      <td>2024-05-03 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-06</th>\n",
       "      <td>2024-05-06 13:30:00+00:00</td>\n",
       "      <td>2024-05-06 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2603 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         market_open              market_close\n",
       "2014-01-02 2014-01-02 14:30:00+00:00 2014-01-02 21:00:00+00:00\n",
       "2014-01-03 2014-01-03 14:30:00+00:00 2014-01-03 21:00:00+00:00\n",
       "2014-01-06 2014-01-06 14:30:00+00:00 2014-01-06 21:00:00+00:00\n",
       "2014-01-07 2014-01-07 14:30:00+00:00 2014-01-07 21:00:00+00:00\n",
       "2014-01-08 2014-01-08 14:30:00+00:00 2014-01-08 21:00:00+00:00\n",
       "...                              ...                       ...\n",
       "2024-04-30 2024-04-30 13:30:00+00:00 2024-04-30 20:00:00+00:00\n",
       "2024-05-01 2024-05-01 13:30:00+00:00 2024-05-01 20:00:00+00:00\n",
       "2024-05-02 2024-05-02 13:30:00+00:00 2024-05-02 20:00:00+00:00\n",
       "2024-05-03 2024-05-03 13:30:00+00:00 2024-05-03 20:00:00+00:00\n",
       "2024-05-06 2024-05-06 13:30:00+00:00 2024-05-06 20:00:00+00:00\n",
       "\n",
       "[2603 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting schedule of NYSE\n",
    "nyse.schedule(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62695ddf-4cc2-488b-927b-e50d51f095a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse.schedule(start_date, end_date).to_csv(path.join(parent_dir, 'trading_calendat_NYSE.csv'), \\\n",
    "                                                     index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4b13df1-4733-4b82-8ff2-a6b0b1bf7fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.datetime64('2200-06-19'),\n",
       " numpy.datetime64('2200-07-04'),\n",
       " numpy.datetime64('2200-09-01'),\n",
       " numpy.datetime64('2200-11-27'),\n",
       " numpy.datetime64('2200-12-25'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting only holidays (exluding wekeends) \n",
    "nyse.holidays().holidays[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0c72473-32ba-446b-8b51-66e7d765a6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2014-01-02 00:00:00+00:00', '2014-01-03 00:00:00+00:00',\n",
       "               '2014-01-06 00:00:00+00:00', '2014-01-07 00:00:00+00:00',\n",
       "               '2014-01-08 00:00:00+00:00', '2014-01-09 00:00:00+00:00',\n",
       "               '2014-01-10 00:00:00+00:00', '2014-01-13 00:00:00+00:00',\n",
       "               '2014-01-14 00:00:00+00:00', '2014-01-15 00:00:00+00:00',\n",
       "               ...\n",
       "               '2024-04-23 00:00:00+00:00', '2024-04-24 00:00:00+00:00',\n",
       "               '2024-04-25 00:00:00+00:00', '2024-04-26 00:00:00+00:00',\n",
       "               '2024-04-29 00:00:00+00:00', '2024-04-30 00:00:00+00:00',\n",
       "               '2024-05-01 00:00:00+00:00', '2024-05-02 00:00:00+00:00',\n",
       "               '2024-05-03 00:00:00+00:00', '2024-05-06 00:00:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', length=2603, freq=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get iterable object of all trading days\n",
    "nyse.valid_days(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37554dcd-0f45-4007-a76c-1deb3fda5f14",
   "metadata": {},
   "source": [
    "## S&P500 and US GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac21848-7b36-4cb2-a26c-ea933577c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alpha_vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f91023-ee06-4f37-b0f1-bbcd6d13a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitation: 25 requests per day\n",
    "key = 'LYET8836ZF7IKTSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2de870b-52fc-45eb-be44-99743a324edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "def USA_index_parsing(save_path, key):\n",
    "    '''\n",
    "    save_path: str or path-object - path to save parsed file\n",
    "    key: str - api_key for AlphaVantageAPI\n",
    "\n",
    "    returns\n",
    "    saves S&P500 historical prices up to date as a csv file \n",
    "    '''\n",
    "    ts = TimeSeries(key) # special alpha vantage api object\n",
    "\n",
    "    # Getting close, high, low, open and volume for S&P500 \n",
    "    # all available historical data\n",
    "    \n",
    "    data, meta_data = ts.get_daily(symbol='SPY', outputsize='full')\n",
    "    df = pd.DataFrame(data).T.reset_index().rename({'index': 'date'}, axis= 1)\n",
    "    for column in df.columns:\n",
    "        if column[0].isdigit():\n",
    "            df.rename({column: column[3:]}, axis = 1, inplace = True)\n",
    "\n",
    "    df.to_csv(path.join(save_path, 'S&P500.csv'), \\\n",
    "              index = False, encoding = 'utf-8')\n",
    "    print('Parsing is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a17c95c3-d690-4795-846f-05da11aeaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_usa_gdp(save_path, key):\n",
    "    '''\n",
    "    save_path: str or path-object - path to save parsed file\n",
    "    key: str - api_key for AlphaVantageAPI\n",
    "\n",
    "    returns\n",
    "    saves real US GDP historical values (quarterly data) as a csv file \n",
    "    '''\n",
    "    # Getting real US GDP through link alpha vantage api\n",
    "    url = f'https://www.alphavantage.co/query?function=REAL_GDP&interval=quarterly&apikey={key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['date'] = df['data'].apply(lambda x: x['date'])\n",
    "    df['value'] = df['data'].apply(lambda x: x['value'])\n",
    "    df.drop('data', axis = 1).to_csv(path.join(save_path, 'GDP_USA.csv'), \\\n",
    "                                     index = False, encoding = 'utf-8')\n",
    "    print('Parsing is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8afa0391-a249-42da-a040-c7443705940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing is done!\n",
      "Parsing is done!\n"
     ]
    }
   ],
   "source": [
    "# example of usage\n",
    "save_path = r'C:\\Users\\Никита\\Андан\\Project\\data\\macro'\n",
    "USA_index_parsing(save_path, key)\n",
    "parse_usa_gdp(save_path, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12a049-79f4-4e4e-a4b0-ac9bbfe383a0",
   "metadata": {},
   "source": [
    "## EFFR\n",
    "\n",
    "Federal Funds Effective Rate. [More about it](https://www.newyorkfed.org/markets/reference-rates/effr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f243bd2-1fb3-4943-be41-8386a5933b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_effr(driver_path, save_path):\n",
    "    '''\n",
    "    driver_path: str or path-object - path to webriver for Selenium\n",
    "    save_path: str or path-object - path to save parsed file\n",
    "\n",
    "    returns \n",
    "    saves EFFR monthly data as a csv file\n",
    "    '''\n",
    "\n",
    "    # extracting link from FRED website\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "    try:\n",
    "        driver.get('https://fred.stlouisfed.org/series/FEDFUNDS')\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"download-button\"))\n",
    "        )\n",
    "        element.click()\n",
    "    \n",
    "        time.sleep(5)\n",
    "        html_content = driver.page_source\n",
    "        driver.quit()\n",
    "    except:\n",
    "        driver.quit()\n",
    "\n",
    "    link = BeautifulSoup(html_content, 'html.parser').\\\n",
    "    find_all('a', {'class': 'dropdown-item fg-download-csv-chart-gtm fg-download-gtm', \\\n",
    "                   'id': \"download-data-csv\"})[0].\\\n",
    "                                                get('href')\n",
    "\n",
    "    # parsing interest rates\n",
    "    responce = requests.get(r'https://fred.stlouisfed.org' + link)\n",
    "    with open(path.join(save_path, 'EFFR.csv'), 'wb') as file:\n",
    "        file.write(responce.content)\n",
    "    \n",
    "    print('Parsing is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ff89020-149d-4ef6-9da7-73a08f064cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing is done!\n"
     ]
    }
   ],
   "source": [
    "parse_effr(PATH, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
